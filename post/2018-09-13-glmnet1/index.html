<!DOCTYPE html>
<html>

<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    
    <meta http-equiv="content-language" content="zh-CN" />
    

    
    <meta name="viewport" content="width=device-width, initial-scale=0.5">
    

    
    <title>glmnet包解读1</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.8/clipboard.min.js"></script>
    
    
    
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap.min.css">

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap-theme.min.css">

    <link rel="stylesheet" href="/css/stylesheet.css">
    <link rel="stylesheet" href="/css/home.css">

    
    
        <style type="text/css">
        body { background-color: #fbf6ec;}
        </style>
    
    
                
        
        
            <link rel="stylesheet" href="/css/main.css"/>
        




        
        
        
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.3.2/styles/github.min.css"  />
         
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.3.2/highlight.min.js"></script>
        
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.3.2/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.3.2/languages/yaml.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.3.2/languages/latex.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.3.2/languages/matlab.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.3.2/languages/mathematica.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.3.2/languages/julia.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.3.2/languages/julia-repl.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.3.2/languages/powershell.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.3.2/languages/bash.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.3.2/languages/shell.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.3.2/languages/python.min.js"></script>
        
        <script>hljs.initHighlightingOnLoad();</script>
     <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
          
     <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css" integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA==" crossorigin="anonymous" />
     
     
</head>


<body>
    <script>
        window.addEventListener("resize", resizeThrottler, false);

        var resizeTimeout;
        function resizeThrottler() {
        
        if ( !resizeTimeout ) {
            resizeTimeout = setTimeout(function() {
            resizeTimeout = null;
            actualResizeHandler();
        
            
            }, 66);
        }
        }
        actualResizeHandler()
        function actualResizeHandler() {
                if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
                {
                    document.body.classList.add('mobile');
                }else{
                    document.body.classList.remove('mobile');  
                }
    }</script>

    
      
      
            <nav class="navbar navbar-default navbar-static-top" style="opacity: .9" role="navigation">
        <div class="container-fluid">
            
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">

                    <span class="sr-only">Toggle navigation</span>
                    <span class="big-icon icon-bar"></span>
                    <span class="big-icon icon-bar"></span>
                    <span class="big-icon icon-bar"></span>

                </button>
                <a class="navbar-brand" href="/">zsc</a>
            </div>

            <div class="navbar-collapse collapse" id="bs-example-navbar-collapse-1" style="height: auto;">
                <ul class="nav navbar-nav navbar-right" style="font-size: 100%">
                    
                        
                            
                            <li class=""><a href="/about/">About</a></li>
                            
                            <li class=""><a href="/categories/">Categories</a></li>
                            
                            <li class=""><a href="/">Home</a></li>
                            
                            <li class=""><a href="/tags/">Tags</a></li>
                            
                            <li class=""><a href="/issue/">存在的问题</a></li>
                            
                        
                    
                </ul>
            </div>
        </div>
    </nav>










<div class="inner">
    



    <div class="blog-post">
        
                <div>
            <h2 align="center" id = "singe-h2">
                glmnet包解读1
                <time>
                    <br>
                    <span> 
                        <i class="fa fa-user-edit" style="color:#888;font-size: 80%;"></i>
                        zsc 
                    </span>
                    &nbsp 
                    <span>                 
                        <i class="fa fa-calendar-alt" style="color:#888;font-size: 80%;"></i>
                        2018-09-13 
                    </span>
                </time>
                
                
                <div>
                    <ul class="tags">
                        
                        <span>标签:</span>
                        <li><a class="link" href="/tags/r"> #r </a></li>
                        
                        <span> </span>
                        
                    </ul>
                    
                </div>
            </h2>
        </div>
    
        
        <section id="content">
            
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#介绍">1 介绍</a></li>
<li><a href="#快速开始">2 快速开始</a></li>
<li><a href="#线性回归">3 线性回归</a>
<ul>
<li><a href="#高斯簇">3.1 高斯簇</a></li>
<li><a href="#多响应高斯簇">3.2 多响应高斯簇</a></li>
</ul></li>
<li><a href="#逻辑回归">4 逻辑回归</a>
<ul>
<li><a href="#二项分布逻辑回归">4.1 二项分布逻辑回归</a></li>
<li><a href="#多分类逻辑回归">4.2 多分类逻辑回归</a></li>
</ul></li>
<li><a href="#泊松回归">5 泊松回归</a>
<ul>
<li><a href="#加载数据集">5.1 加载数据集</a></li>
<li><a href="#拟合模型-4">5.2 拟合模型</a></li>
<li><a href="#查看拟合效果-3">5.3 查看拟合效果</a></li>
<li><a href="#预测-3">5.4 预测</a></li>
</ul></li>
<li><a href="#cox模型">6 Cox模型</a>
<ul>
<li><a href="#载入数据集">6.1 载入数据集</a></li>
<li><a href="#拟合模型-5">6.2 拟合模型</a></li>
<li><a href="#查看拟合效果-4">6.3 查看拟合效果</a></li>
<li><a href="#交叉验证-4">6.4 交叉验证</a></li>
</ul></li>
<li><a href="#稀疏矩阵">7 稀疏矩阵</a></li>
</ul>
</div>

<div id="介绍" class="section level2">
<h2>1 介绍</h2>
<p><code>glmnet</code> 包解决了一下问题（目标函数）
<span class="math display">\[
\min_{\beta_0,\beta} \frac{1}{N} \sum_{i=1}^{N} w_i l(y_i,\beta_0+\beta^T x_i) + \lambda\left[(1-\alpha)||\beta||_2^2/2 + \alpha ||\beta||_1\right],
\]</span>
#### 1.1 glmnet包安装</p>
<pre class="r"><code>install.packages(&quot;glmnet&quot;, repos = &quot;http://cran.us.r-project.org&quot;)</code></pre>
</div>
<div id="快速开始" class="section level2">
<h2>2 快速开始</h2>
<p>这节介绍<code>glmnet</code>包中的主要函数以及它们的一般用法，对常用函数的输入参数以及输出结果做简要的说明。</p>
<div id="加载glmnet包" class="section level4">
<h4>2.1 加载glmnet包</h4>
<pre class="r"><code>library(glmnet)# 加载glmnet包</code></pre>
<p>以线性回归为例，来说明<code>glmnet</code>包的用法。</p>
</div>
<div id="准备数据" class="section level4">
<h4>2.2 准备数据</h4>
<pre class="r"><code>data(QuickStartExample)#x为100*20的矩阵 ,y为100 * 1的矩阵。</code></pre>
<p>该命令R数据存档中加载输入矩阵<code>x</code>和响应向量<code>y</code>。 <code>x</code>为<code>100*20</code>的矩阵 ,<code>y</code>为<code>100 * 1</code>的矩阵。</p>
</div>
<div id="拟合模型" class="section level4">
<h4>2.3 拟合模型</h4>
<p>数据有了，我们就可以调用包中与之同名的<code>glmnet</code>函数来做线性回归了：</p>
<pre class="r"><code>fit = glmnet(x, y)</code></pre>
<p>这里生成的结果 “fit”是类的对象<code>glmnet</code>，包含拟合模型的所有相关信息。不鼓励用户直接提取组件（像list那样提取）。推荐使用各种方法<code>plot</code>，<code>print</code>，<code>coef</code>和<code>predict</code>提取信息，这样能够使我们更优雅执行这些任务。</p>
</div>
<div id="模型对象的可视化" class="section level4">
<h4>2.4 模型对象的可视化</h4>
<p>采用<code>plot</code>函数对拟合出的模型系数进行可视化：</p>
<pre class="r"><code># label = T，可以显示变量的标签。
# 参数xvar = c(&quot;norm&quot;, &quot;lambda&quot;, &quot;dev&quot;)
# norm（默认）:  显示系数值和L1范数之间的变化关系
# lambda： 显示系数值和对数lambda之间的变化关系
# dev : 显示系数值如何随解释偏差百分比（dev）之间的变化关系
plot(fit,label = T)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>上图中，每一条曲线代表一个变量的系数。Y轴是回归系数的值，X轴是L1范数，图中上方有另一条x轴，其数值表示模型的特征数，</p>
</div>
<div id="模型对象信息的提取" class="section level4">
<h4>2.5 模型对象信息的提取</h4>
<p>回到我们的拟合结果<code>fit</code>。作为一个 R 对象，我们可以把它当作很多函数的输入。比如说，我们可以查看详细的拟合结果：</p>
<pre class="r"><code>print(fit)
#&gt; 
#&gt; Call:  glmnet(x = x, y = y) 
#&gt; 
#&gt;    Df  %Dev  Lambda
#&gt; 1   0  0.00 1.63100
#&gt; 2   2  5.53 1.48600
#&gt; 3   2 14.59 1.35400
#&gt; 4   2 22.11 1.23400
#&gt; 5   2 28.36 1.12400
#&gt; 6   2 33.54 1.02400
#&gt; 7   4 39.04 0.93320
#&gt; 8   5 45.60 0.85030
#&gt; 9   5 51.54 0.77470
#&gt; 10  6 57.35 0.70590
#&gt; 11  6 62.55 0.64320
#&gt; 12  6 66.87 0.58610
#&gt; 13  6 70.46 0.53400
#&gt; 14  6 73.44 0.48660
#&gt; 15  7 76.21 0.44330
#&gt; 16  7 78.57 0.40400
#&gt; 17  7 80.53 0.36810
#&gt; 18  7 82.15 0.33540
#&gt; 19  7 83.50 0.30560
#&gt; 20  7 84.62 0.27840
#&gt; 21  7 85.55 0.25370
#&gt; 22  7 86.33 0.23120
#&gt; 23  8 87.06 0.21060
#&gt; 24  8 87.69 0.19190
#&gt; 25  8 88.21 0.17490
#&gt; 26  8 88.65 0.15930
#&gt; 27  8 89.01 0.14520
#&gt; 28  8 89.31 0.13230
#&gt; 29  8 89.56 0.12050
#&gt; 30  8 89.76 0.10980
#&gt; 31  9 89.94 0.10010
#&gt; 32  9 90.10 0.09117
#&gt; 33  9 90.23 0.08307
#&gt; 34  9 90.34 0.07569
#&gt; 35 10 90.43 0.06897
#&gt; 36 11 90.53 0.06284
#&gt; 37 11 90.62 0.05726
#&gt; 38 12 90.70 0.05217
#&gt; 39 15 90.78 0.04754
#&gt; 40 16 90.86 0.04331
#&gt; 41 16 90.93 0.03947
#&gt; 42 16 90.98 0.03596
#&gt; 43 17 91.03 0.03277
#&gt; 44 17 91.07 0.02985
#&gt; 45 18 91.11 0.02720
#&gt; 46 18 91.14 0.02479
#&gt; 47 19 91.17 0.02258
#&gt; 48 19 91.20 0.02058
#&gt; 49 19 91.22 0.01875
#&gt; 50 19 91.24 0.01708
#&gt; 51 19 91.25 0.01557
#&gt; 52 19 91.26 0.01418
#&gt; 53 19 91.27 0.01292
#&gt; 54 19 91.28 0.01178
#&gt; 55 19 91.29 0.01073
#&gt; 56 19 91.29 0.00978
#&gt; 57 19 91.30 0.00891
#&gt; 58 19 91.30 0.00812
#&gt; 59 19 91.31 0.00739
#&gt; 60 19 91.31 0.00674
#&gt; 61 19 91.31 0.00614
#&gt; 62 20 91.31 0.00559
#&gt; 63 20 91.31 0.00510
#&gt; 64 20 91.31 0.00464
#&gt; 65 20 91.32 0.00423
#&gt; 66 20 91.32 0.00386
#&gt; 67 20 91.32 0.00351</code></pre>
<p>每一行代表了一个模型 ,它从左到右显示非零系数的个数（<code>Df</code>），模型所解释的偏差的百分比（<code>%dev</code>）和λ的值（<code>Lambda</code>） （注意岭回归中列<code>Df</code>的值是不会变的）</p>
<p>通过<code>coef</code>来提取模型的系数：</p>
<pre class="r"><code># 参数s：指定lambda的值，可以是一个向量，则提取多个模型的系数，每一列对应一个模型的系数
# 参数complete: 逻辑值,表示是否应该返回全系数向量.
coef(fit,s=0.1,exact=FALSE)
#&gt; 21 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
#&gt;                        1
#&gt; (Intercept)  0.150928072
#&gt; V1           1.320597195
#&gt; V2           .          
#&gt; V3           0.675110234
#&gt; V4           .          
#&gt; V5          -0.817411518
#&gt; V6           0.521436671
#&gt; V7           0.004829335
#&gt; V8           0.319415917
#&gt; V9           .          
#&gt; V10          .          
#&gt; V11          0.142498519
#&gt; V12          .          
#&gt; V13          .          
#&gt; V14         -1.059978702
#&gt; V15          .          
#&gt; V16          .          
#&gt; V17          .          
#&gt; V18          .          
#&gt; V19          .          
#&gt; V20         -1.021873704</code></pre>
<p>用<code>coef</code>来提取模型的系数,参数采用的是<code>s</code> 而不是<code>lambda</code>,—同样在<code>predict</code>函数中一样的道理,eg:</p>
</div>
<div id="预测" class="section level4">
<h4>2.6 预测</h4>
<p>预测采用<code>predict</code>函数，参数<code>newx</code>用来设置输入数据，<code>s</code>用来设置<span class="math inline">\(\lambda\)</span>的值：</p>
<pre class="r"><code>nx = matrix(rnorm(10*20),10,20)
#predict函数与coef函数相比多了一些参数的设置，参数newx设置待预测的输入数据集，以及tpye参数选项
predict(fit,newx=nx,s=c(0.1,0.05))
#&gt;                 1           2
#&gt;  [1,]  0.87898550  0.96764179
#&gt;  [2,]  2.29343179  2.44816869
#&gt;  [3,] -0.08536714  0.01529541
#&gt;  [4,] -1.09721678 -1.27596245
#&gt;  [5,]  0.48922414  0.49592697
#&gt;  [6,] -0.78042430 -0.84473032
#&gt;  [7,] -1.04741846 -1.00724387
#&gt;  [8,] -2.54927346 -2.81992948
#&gt;  [9,] -2.40041719 -2.55525374
#&gt; [10,]  1.67434591  1.92094822</code></pre>
</div>
<div id="交叉验证" class="section level4">
<h4>2.7 交叉验证</h4>
<p><code>glmnet</code>提供了一系列的模型可供选择，而在大多数情况下我们需要从中挑选出一个最合适的来用就可以了。这时可以通过交叉验证的方法来筛选最优的λ值了，<code>cv.glmnet</code>函数实现了这一功能。 也支持绘图和预测方法。</p>
<p>继续沿用之前的样本数据，调用<code>cv.glmnet</code>函数：</p>
<pre class="r"><code>cvfit = cv.glmnet(x, y)</code></pre>
<p>可以看到，<code>cv.glmnet</code>返回的结果是一个<code>cv.glmnet</code>类的对象，该对象的类型和<code>glmnet</code>函数返回的结果一样，它们本质上都是R中的list。 不鼓励直接提取信息，推荐使用各种函数提取.</p>
<p>我们用可视化的图形来展示<code>cv.glmnet</code>的结果：</p>
<pre class="r"><code>plot(cvfit)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>从图中可以看到MSE是如何随着lambda的不同取值而变化的。红色的散点为交叉验证的散点图，横轴为logλ，纵轴为均方误差，每个点的标准偏差上界和下界也画出来了。图的顶部字数表示非零系数的个数，第一条垂直线对应的是lambda.min的值，它是交叉验证提取出的最优值，第二条（从左往右看）是lambda.lse属性的值，它对应了距离lambda.min一个标准误差的值，并产生了一个更为正则化的模型 （<code>lambda.1se</code>为离最小均方误差一倍标准差的λ值。 ）</p>
<p>最优的λ 值可以直接采用如下命令来提取：</p>
<pre class="r"><code>cvfit$lambda.min
#&gt; [1] 0.08307327
cvfit$lambda.1se
#&gt; [1] 0.1451729</code></pre>
<p>用<code>coef</code>函数来提取回归模型的系数：</p>
<pre class="r"><code>coef(cvfit, s = &quot;lambda.min&quot;)
#&gt; 21 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
#&gt;                       1
#&gt; (Intercept)  0.14936467
#&gt; V1           1.32975267
#&gt; V2           .         
#&gt; V3           0.69096092
#&gt; V4           .         
#&gt; V5          -0.83122558
#&gt; V6           0.53669611
#&gt; V7           0.02005438
#&gt; V8           0.33193760
#&gt; V9           .         
#&gt; V10          .         
#&gt; V11          0.16239419
#&gt; V12          .         
#&gt; V13          .         
#&gt; V14         -1.07081121
#&gt; V15          .         
#&gt; V16          .         
#&gt; V17          .         
#&gt; V18          .         
#&gt; V19          .         
#&gt; V20         -1.04340741</code></pre>
<p>可以看到回归模型的系数是采用稀疏矩阵的形式来存储的。由于计算出的模型系数经常是稀疏的，这时采用稀疏矩阵的方式来存储和计算更有效率。如果你不习惯稀疏矩阵的输出形式，可以用<code>as.matrix()</code>将其转化为传统的矩阵形式。</p>
<p>预测同<code>glmnet</code>，直接采用<code>predict</code>泛型函数即可：</p>
<pre class="r"><code>predict(cvfit, newx = x[1:5,], s = &quot;lambda.min&quot;)
#&gt;               1
#&gt; [1,] -1.3647490
#&gt; [2,]  2.5686013
#&gt; [3,]  0.5705879
#&gt; [4,]  1.9682289
#&gt; [5,]  1.4964211</code></pre>
<p>自此，<code>glmnet</code>的入门介绍完了，你可以用来他做一些基本的回归模型了。</p>
<p>接下来，我们对<code>glmnet</code>包进行更为深入的介绍。</p>
</div>
</div>
<div id="线性回归" class="section level2">
<h2>3 线性回归</h2>
<p><code>glmnet</code>中的线性回归主要包含两类。一定是高斯簇<code>gaussian</code>，还有一类是多响应高斯簇<code>mgaussian</code>。我们依次介绍：</p>
<div id="高斯簇" class="section level3">
<h3>3.1 高斯簇</h3>
<p><code>gaussian</code> 是<code>glmnet</code>函数中的默认函数簇，它本质上是带正则项的多元线性回归的估计问题。</p>
<div id="优化目标" class="section level4">
<h4>3.1.1 优化目标</h4>
<p>优化的目标函数如下：（高斯族采用的是平方损失函数）
<span class="math display">\[
\min_{(\beta_0, \beta) \in \mathbb{R}^{p+1}}\frac{1}{2N} \sum_{i=1}^N (y_i -\beta_0-x_i^T \beta)^2+\lambda \left[ \dfrac{1}{2}(1-\alpha)||\beta||_2^2 + \alpha||\beta||_1\right],
\]</span>
其中 <span class="math inline">\(\lambda \geq 0\)</span> 是模型复杂度参数 ;<span class="math inline">\(0 \leq \alpha \leq 1\)</span> ，当<span class="math inline">\(\alpha = 0\)</span> 时为岭回归，当<span class="math inline">\(\alpha = 1\)</span>为lasso，在<span class="math inline">\(0 &lt;\alpha &lt; 1\)</span>则为两者的折中.</p>
</div>
<div id="glmnet参数设置" class="section level4">
<h4>3.1.2 glmnet参数设置</h4>
<p><code>glmnet</code>提供了很多参数可以供我们选择。下面介绍一些常用的参数设置：</p>
<ul>
<li><code>alpha</code>之前介绍过，它是弹性网的参数，取值范围是[0, 1], (且只能一个一个取，不能为向量)</li>
<li><code>weights</code>配置观测的权重。默认每个观测的权重取值均为1。</li>
<li><code>nlambda</code>默认值是100。(系统自动挑选 100 个不同的 λ 值，拟合出 100 个系数不同的模型 ）</li>
<li><code>lambda</code>一般是程序自动构建，也可以自己定义（可以是向量）。</li>
<li><code>standardize</code>表示在拟合模型前，<code>x</code>变量是否需要标准化。默认<code>standardize=TRUE</code>。</li>
</ul>
<p>更多参数设置参考帮助文档<code>help(glmnet)</code>。</p>
<p>我们用下面的例子来看看这些参数的用法： 还是用原来的样本数据，不同的是取α = 0.2（接近岭回归的正则项），设置观测的权重以及 λ序列的数量：</p>
<pre class="r"><code>fit = glmnet(x, y, alpha = 0.2, weights = c(rep(1,50),rep(2,50)), nlambda = 20)</code></pre>
<p>用<code>print</code>函数打印结果：</p>
<pre class="r"><code>print(fit)
#&gt; 
#&gt; Call:  glmnet(x = x, y = y, weights = c(rep(1, 50), rep(2, 50)), alpha = 0.2,      nlambda = 20) 
#&gt; 
#&gt;    Df  %Dev Lambda
#&gt; 1   0  0.00 7.9390
#&gt; 2   4 17.89 4.8890
#&gt; 3   7 44.45 3.0110
#&gt; 4   7 65.67 1.8540
#&gt; 5   8 78.50 1.1420
#&gt; 6   9 85.39 0.7033
#&gt; 7  10 88.67 0.4331
#&gt; 8  11 90.25 0.2667
#&gt; 9  14 91.01 0.1643
#&gt; 10 17 91.38 0.1012
#&gt; 11 17 91.54 0.0623
#&gt; 12 17 91.60 0.0384
#&gt; 13 19 91.63 0.0236
#&gt; 14 20 91.64 0.0146
#&gt; 15 20 91.64 0.0090
#&gt; 16 20 91.65 0.0055
#&gt; 17 20 91.65 0.0034</code></pre>
<p>打印结果之前已做过说明，这里不再赘述。可以看到这里λ并没有达到预设的20。这是因为在偏差解释率达到0.999或者其变化小于10e-5时计算就会终止。而这些预设的计算终止条件可以通过<code>glmnet.control</code>来设置，详见<code>help(glmnet.control)</code>。</p>
<p>注意，可以设置<code>digits</code>选项可用于指定打印输出中的有效数字</p>
</div>
<div id="plot参数设置" class="section level4">
<h4>3.1.3 plot参数设置</h4>
<p>Y轴为模型的系数值。</p>
<p><code>plot</code>函数可以用<code>xvar</code>来定义X轴的度量，有三种选项：</p>
<ul>
<li>“norm” 表示系数的L1-范数(默认)，显示系数值和L1范数之间的变化关系</li>
<li>“lambda” 表示对数lambda值，显示系数值和对数lambda之间的变化关系</li>
<li>“dev” 表示偏差解释率，显示系数值如何随解释偏差百分比（dev）之间的变化关系</li>
</ul>
<p>在<code>plot</code>函数中添加参数<code>label = TRUE</code>可以显示变量的标签</p>
<pre class="r"><code>layout(matrix(c(1,2,3),1,3))
plot(fit, xvar = &quot;norm&quot;, label = TRUE,main=&#39;nrom\n&#39;)
plot(fit, xvar = &quot;lambda&quot;, label = TRUE,main=&#39;lambda\n&#39;)
plot(fit, xvar = &quot;dev&quot;, label = TRUE,main=&#39;dev\n&#39;)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>每一条曲线代表一个变量的系数。Y轴是回归系数的值，X轴是L1范数(默认)，图中上方有另一条x轴，其数值表示模型的特征数，</p>
</div>
<div id="coef参数设置" class="section level4">
<h4>3.1.4 coef参数设置</h4>
<p>coef函数中最常用的两个参数为:</p>
<ul>
<li><code>s</code> 指定λ值</li>
<li><code>complete</code> 表示是否应该返回全系数向量.</li>
</ul>
<pre class="r"><code>any(fit$lambda == 0.5)
#&gt; [1] FALSE
coef.exact = coef(fit, s = 0.5, complete = TRUE)
coef.apprx = coef(fit, s = 0.5, complete = FALSE)
cbind2(coef.exact, coef.apprx)
#&gt; 21 x 2 sparse Matrix of class &quot;dgCMatrix&quot;
#&gt;                        1            1
#&gt; (Intercept)  0.199098747  0.199098747
#&gt; V1           1.174650452  1.174650452
#&gt; V2           .            .          
#&gt; V3           0.531934651  0.531934651
#&gt; V4           .            .          
#&gt; V5          -0.760959480 -0.760959480
#&gt; V6           0.468209414  0.468209414
#&gt; V7           0.061926756  0.061926756
#&gt; V8           0.380301491  0.380301491
#&gt; V9           .            .          
#&gt; V10          .            .          
#&gt; V11          0.143260991  0.143260991
#&gt; V12          .            .          
#&gt; V13          .            .          
#&gt; V14         -0.911207368 -0.911207368
#&gt; V15          .            .          
#&gt; V16          .            .          
#&gt; V17          .            .          
#&gt; V18          0.009196629  0.009196629
#&gt; V19          .            .          
#&gt; V20         -0.863117051 -0.863117051</code></pre>
<p>结论： 当<code>exact</code>选取不同的参数时，提取的系数也存在一定程度的差异，但差距不大。没有特别要求的话，使用线性插值得到的结果已经够用了。</p>
</div>
<div id="predict参数设置" class="section level4">
<h4>3.1.5 predict参数设置</h4>
<p><code>predict</code>函数与<code>coef</code>函数相比多了一些参数的设置：<code>newx</code>是待预测的输入数据集。</p>
<p><code>type</code>有多个选项可供选择：</p>
<ul>
<li>“link” 给出预测值</li>
<li>“response” 对于gaussian簇，同“link”</li>
<li>“coefficients” 计算给定<code>s</code>下的系数矩阵</li>
<li>“nonzero” list对象，存储每个<code>s</code>下非0系数对应的下标</li>
</ul>
<pre class="r"><code>predict(fit, newx = x[1:5,], type = &quot;response&quot;, s = 0.05)
#&gt;               1
#&gt; [1,] -0.9802591
#&gt; [2,]  2.2992453
#&gt; [3,]  0.6010886
#&gt; [4,]  2.3572668
#&gt; [5,]  1.7520421</code></pre>
<p>上述命令表示在λ = 0.05时计算<code>x</code>头5条观测的预测值。这里的<code>s</code>可以是一个向量，当<code>s</code>是一个多数值向量时，预测值则为一个矩阵。</p>
</div>
<div id="交叉验证-1" class="section level4">
<h4>3.1.6 交叉验证</h4>
<div id="普通计算" class="section level5">
<h5>3.1.6.1 普通计算</h5>
<p>这小节对<code>cv.glmnet</code>函数的参数做简要说明：</p>
<ul>
<li><code>nfolds</code> – 交叉验证数据集划分的份数</li>
<li><code>foldid</code> – 自定义划分数据</li>
<li><code>type.measure</code> – 定义交叉验证的损失函数，“deviance”和“mse”用的是平方损失，“mae”用的是平均绝对损失</li>
</ul>
<p>举一个列子：</p>
<pre class="r"><code># 做20重交叉验证，采用平均绝对损失
cvfit &lt;- cv.glmnet(x, y, type.measure = &quot;mse&quot;, nfolds = 20)</code></pre>
</div>
<div id="并行计算" class="section level5">
<h5>3.1.6.2 并行计算</h5>
<p><code>cv.glmnet</code>也支持并行计算，不过要使其工作，用户必须加载<code>doMC</code>并注册并行数量. 在这里给出一个简单的比较示例。 (不过很遗憾，win不能用)</p>
<pre class="r"><code>require(doMC) # win不能用,可以下载下来，但是不能平行计算。
# install.packages(&quot;doMC&quot;, repos=&quot;http://R-Forge.R-project.org&quot;)
registerDoMC(cores=2)
X = matrix(rnorm(1e4 * 200), 1e4, 200)
Y = rnorm(1e4)
system.time(cv.glmnet(X, Y))
#&gt;  用户  系统  流逝 
#&gt; 3.455 0.334 3.850
system.time(cv.glmnet(X, Y, parallel = TRUE))
#&gt;  用户  系统  流逝 
#&gt; 3.525 0.530 2.511</code></pre>
<pre class="r"><code># 看了一下帮助文档 可以改成doParallel 也不能用很奇怪
library(doParallel)
# Windows 可以使用的并行包，但在这里也不能进行并行计算，时间不变
cl&lt;-makeCluster(6)
registerDoParallel(cl)
system.time({cvfit = cv.glmnet(x,y,parallel=TRUE)})
#&gt;  用户  系统  流逝 
#&gt; 0.074 0.002 5.215
stopCluster(cl)# 时间也没有明显提高</code></pre>
<p>如上所述，并行计算可以显着加速计算过程，尤其是对于大规模问题。</p>
</div>
<div id="提取最优参数" class="section level5">
<h5><strong>3.1.6.3 提取最优参数</strong></h5>
<p>函数 <code>coef</code> 和 <code>predict</code> 处理<code>cv.glmnet</code> 对象和处理 <code>glmnet</code> 对象类似。不过处理<code>cv.glmnet</code>对象时，在指定<span class="math inline">\(s\)</span>参数是可以用两个特殊的字符:<code>lambda.1se</code>和<code>lambda.min</code></p>
<ul>
<li>“lambda.1se”: 为离最小均方误差MSE一倍标准差的<span class="math inline">\(\lambda\)</span>值。</li>
<li>“lambda.min”: 达到最小MSE对应的<span class="math inline">\(\lambda\)</span>值（即 交叉验证提取出的最优值）</li>
</ul>
<pre class="r"><code>cvfit$lambda.min
#&gt; [1] 0.07569327
coef(cvfit, s = &quot;lambda.min&quot;)
#&gt; 21 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
#&gt;                       1
#&gt; (Intercept)  0.14867414
#&gt; V1           1.33377821
#&gt; V2           .         
#&gt; V3           0.69787701
#&gt; V4           .         
#&gt; V5          -0.83726751
#&gt; V6           0.54334327
#&gt; V7           0.02668633
#&gt; V8           0.33741131
#&gt; V9           .         
#&gt; V10          .         
#&gt; V11          0.17105029
#&gt; V12          .         
#&gt; V13          .         
#&gt; V14         -1.07552680
#&gt; V15          .         
#&gt; V16          .         
#&gt; V17          .         
#&gt; V18          .         
#&gt; V19          .         
#&gt; V20         -1.05278699
predict(cvfit, newx = x[1:5,], s = &quot;lambda.min&quot;)
#&gt;               1
#&gt; [1,] -1.3638848
#&gt; [2,]  2.5713428
#&gt; [3,]  0.5729785
#&gt; [4,]  1.9881422
#&gt; [5,]  1.5179882</code></pre>
</div>
<div id="数据划分问题" class="section level5">
<h5>3.1.6.4 数据划分问题</h5>
<p>除了可以设置<code>nfolds</code>来寻找合适的模型外，我们还可以通过<code>foldid</code>设置相同的数据划分来选择最优的α值。</p>
<pre class="r"><code>foldid=sample(1:10,size=length(y),replace=TRUE)
cv1=cv.glmnet(x,y,foldid=foldid,alpha=1)
cv.5=cv.glmnet(x,y,foldid=foldid,alpha=.5)
cv0=cv.glmnet(x,y,foldid=foldid,alpha=0)</code></pre>
<p>进行对比</p>
<pre class="r"><code>par(mfrow=c(2,2))
plot(cv1);plot(cv.5);plot(cv0)
plot(log(cv1$lambda),cv1$cvm,pch=19,col=&quot;red&quot;,xlab=&quot;log(Lambda)&quot;,ylab=cv1$name)
points(log(cv.5$lambda),cv.5$cvm,pch=19,col=&quot;grey&quot;)
points(log(cv0$lambda),cv0$cvm,pch=19,col=&quot;blue&quot;)
legend(&quot;topleft&quot;,legend=c(&quot;alpha= 1&quot;,&quot;alpha= .5&quot;,&quot;alpha 0&quot;),pch=19,col=c(&quot;red&quot;,&quot;grey&quot;,&quot;blue&quot;))</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>我们可以看到这里选择lasso(<code>alpha=1</code>)时，模型的均方误差最小。</p>
</div>
</div>
<div id="系数上限和下限" class="section level4">
<h4>3.1.7 系数上限和下限</h4>
<p>这些是最近添加的功能，可以增强模型的范围。假设我们想要拟合我们的模型，但是要将系数限制为大于-0.7且小于0.5。这可以通过<code>upper.limits</code>和<code>lower.limits</code>参数轻松实现：</p>
<pre class="r"><code>tfit=glmnet(x,y,lower=-.7,upper=.5)
plot(tfit)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>这些是相当随意的限制; 通常我们希望系数为正，所以我们只能设置<code>lower.limit</code>为0</p>
<blockquote>
<p>注意,上下限的取值范围 ：upper.limits的值不能小于0，lower.limits的值不能大于0 ,另外，如果想对每一个变量的系数对不同的限定，需要将这里的单点值即标量改为向量的形式就可以了。</p>
</blockquote>
</div>
<div id="惩罚因子" class="section level4">
<h4>3.1.8 惩罚因子</h4>
<p>这个参数可以给每一个系数提供一个单独的惩罚因子。该惩罚因子默认是1，它也支持自定义。如果将惩罚因子全部设置成为0的话，相当于就没有惩罚项了。</p>
<p>看看以下公式就一目了然了：
<span class="math display">\[
\lambda \sum_{j=1}^p \boldsymbol{v_j} P_\alpha(\beta_j) = \lambda \sum_{j=1}^p \boldsymbol{v_j} \left[ (1-\alpha)\frac{1}{2} \beta_j^2 + \alpha |\beta_j| \right].
\]</span>
这个参数设置选项很有用，假如我们知道了一些先验信息，知道了其中一些变量很重要，需要在建模正则化的同时一直保留这些变量，那么可以把这些变量对应系数的惩罚因子设置为0。</p>
<p>同样用之前的数据，我们把第5、10、15个变量对应的惩罚因子设置为0：</p>
<pre class="r"><code>p.fac = rep(1, 20)
p.fac[c(5, 10, 15)] = 0
pfit = glmnet(x, y, penalty.factor = p.fac)
plot(pfit, label = TRUE)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>从上图中可以看到，变量5、10、15对应的系数一直都在模型中。</p>
<p>还有一些其它的有用的参数，比如，<code>exclude</code>参数可以用来限制指定的变量入选模型；<code>intercept</code>参数可以用来设定模型是否含有截距项等等。更多设置参考帮助文档<code>help(cv.glmnet)</code>.</p>
</div>
<div id="自定义图" class="section level4">
<h4>3.1.9 自定义图</h4>
<p>有时，特别是当变量数量很少时，我们希望将变量标签添加到绘图中，而不是用变量的所在数据集中的下标。 如下：简单生成一组数据，拟合一个glmnet模型 ，并画出图</p>
<pre class="r"><code>set.seed(101)
x=matrix(rnorm(1000),100,10)
y=rnorm(100)
vn=paste(&quot;var&quot;,1:10) 
fit=glmnet(x,y)
plot(fit)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>然而我们想要的是用变量名称标记曲线 ，如下：</p>
<pre class="r"><code>par(mar=c(4.5,4.5,1,4))
plot(fit)
vnat=coef(fit)
vnat=vnat[-1,ncol(vnat)] # remove the intercept, and get the coefficients at the end of the path
axis(4, at=vnat,line=-.5,label=vn,las=1,tick=FALSE, cex.axis=0.5)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
</div>
</div>
<div id="多响应高斯簇" class="section level3">
<h3>3.2 多响应高斯簇</h3>
<p>多响应高斯簇模型的估计需要在<code>glmnet</code>函数中设置<code>family = "mgaussian"</code>。与以上单变量响应模型类似，它只是响应变量增多了，我们通常称之为“多任务学习”问题。虽然响应变量增多了，但是建模时所选择的自变量是完全一样的，只是待估系数不同而已。</p>
<p>很显然，模型的因变量不再是一个向量形式，而是一个二维矩阵，这时估计出的系数也会是一个矩阵，先看看多响应高斯簇模型解决的问题：
<span class="math display">\[
\min_{(\beta_0, \beta) \in \mathbb{R}^{(p+1)\times K}}\frac{1}{2N} \sum_{i=1}^N ||y_i -\beta_0-\beta^T x_i||^2_F+\lambda \left[ (1-\alpha)||\beta||_F^2/2 + \alpha\sum_{j=1}^p||\beta_j||_2\right].
\]</span>
这里的βj是<span class="math inline">\(p\times K\)</span>维的系数矩阵<span class="math inline">\(\beta\)</span>的第j行。</p>
<div id="载入演示数据" class="section level4">
<h4>3.2.1 载入演示数据</h4>
<pre class="r"><code>data(MultiGaussianExample)# 产生x,y两个矩阵，x的维度100*20 ,y的维度100 * 4。</code></pre>
</div>
<div id="拟合模型-1" class="section level4">
<h4>3.2.2 拟合模型</h4>
<pre class="r"><code>mfit = glmnet(x, y, family = &quot;mgaussian&quot;)</code></pre>
<p>多响应高斯模型与单响应高斯模型的大部分参数设置相同，如<code>alpha</code>,<code>weights</code>,<code>nlambda</code>,<code>standardize</code>。<strong>但是<code>mgaussian</code>簇有一个额外的参数<code>standardize.response</code>，它可以用来给响应变量做标准化，默认为<code>FALSE</code></strong>。</p>
</div>
<div id="查看拟合效果" class="section level4">
<h4>3.2.3 查看拟合效果</h4>
<p>用<code>plot</code>函数查看系数的变化：</p>
<pre class="r"><code>plot(mfit, xvar = &quot;lambda&quot;, label = TRUE, type.coef = &quot;2norm&quot;)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<pre class="r"><code>plot(mfit, xvar = &quot;lambda&quot;, label = TRUE, type.coef = &quot;coef&quot;)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-31-2.png" width="672" /><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-31-3.png" width="672" /><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-31-4.png" width="672" /><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-31-5.png" width="672" /></p>
<p>其中<code>xvar</code>并且<code>label</code>两个参数的设置与单响应的高斯模型一样 。这里的<code>type.coef = "2norm"</code>表示每个变量的系数以二范数的形式展现。默认设置为<code>type.coef = "coef"</code>，这时每个响应变量会展示一张系数变化的图。</p>
</div>
<div id="预测-1" class="section level4">
<h4>3.2.4 预测</h4>
<p>可以通过<code>coef</code>函数提取系数 ，<code>predict</code>函数进行预测。用法和但响应的高斯模型一样，下面看看<code>predict</code>的用法：</p>
<pre class="r"><code>predict(mfit, newx = x[1:5,], s = c(0.1, 0.01))
#&gt; , , 1
#&gt; 
#&gt;              y1         y2         y3       y4
#&gt; [1,] -4.7106263 -1.1634574  0.6027634 3.740989
#&gt; [2,]  4.1301735 -3.0507968 -1.2122630 4.970141
#&gt; [3,]  3.1595229 -0.5759621  0.2607981 2.053976
#&gt; [4,]  0.6459242  2.1205605 -0.2252050 3.146286
#&gt; [5,] -1.1791890  0.1056262 -7.3352965 3.248370
#&gt; 
#&gt; , , 2
#&gt; 
#&gt;              y1         y2         y3       y4
#&gt; [1,] -4.6415158 -1.2290282  0.6118289 3.779521
#&gt; [2,]  4.4712843 -3.2529658 -1.2572583 5.266039
#&gt; [3,]  3.4735228 -0.6929231  0.4684037 2.055574
#&gt; [4,]  0.7353311  2.2965083 -0.2190297 2.989371
#&gt; [5,] -1.2759930  0.2892536 -7.8259206 3.205211</code></pre>
</div>
<div id="交叉验证-2" class="section level4">
<h4>3.2.5 交叉验证</h4>
<p>同样的交叉验证用<code>cv.glmnet</code>函数：</p>
<pre class="r"><code>cvmfit = cv.glmnet(x, y, family = &quot;mgaussian&quot;)</code></pre>
<p>画出交叉验证的结果：</p>
<pre class="r"><code>plot(cvmfit)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<p>想要查看最优的<span class="math inline">\(\lambda\)</span>,,采用如下命令:</p>
<pre class="r"><code>cvmfit$lambda.min
#&gt; [1] 0.05193158
cvmfit$lambda.1se
#&gt; [1] 0.174054</code></pre>
<p>和以前一样，第一个是达到最小均方误差的值，第二个是最正则化模型，其均方误差在最小值的一个标准误差范围内</p>
</div>
</div>
</div>
<div id="逻辑回归" class="section level2">
<h2>4 逻辑回归</h2>
<p>逻辑回归是分类问题中最常用的模型之一。如果是一个二分类问题，一般假定响应变量服从二项分布，如果是多分类问题，则假定服从多项式分布。</p>
<div id="二项分布逻辑回归" class="section level3">
<h3>4.1 二项分布逻辑回归</h3>
<p>假定响应变量的取值为 <span class="math inline">\(\mathcal{G}=\{1,2\}\)</span>.定义 <span class="math inline">\(y_i = I(g_i=1)\)</span>.则有
<span class="math display">\[\mbox{Pr}(G=2|X=x)+\frac{e^{\beta_0+\beta^Tx}}{1+e^{\beta_0+\beta^Tx}},\]</span>
我们可以两边取对数，改写为如下形式（称为对数似然函数）：
<span class="math display">\[\log\frac{\mbox{Pr}(G=2|X=x)}{\mbox{Pr}(G=1|X=x)}=\beta_0+\beta^Tx,\]</span></p>
<p>这个带惩罚逻辑回归的目标函数的对数似然如下：
<span class="math display">\[
\min_{(\beta_0, \beta) \in \mathbb{R}^{p+1}} -\left[\frac{1}{N} \sum_{i=1}^N y_i \cdot (\beta_0 + x_i^T \beta) - \log (1+e^{(\beta_0+x_i^T \beta)})\right] + \lambda \big[ (1-\alpha)||\beta||_2^2/2 + \alpha||\beta||_1\big].
\]</span>
当 <span class="math inline">\(p &gt; N\)</span> 时，逻辑回归常常伴随着退化的困扰 ，当<span class="math inline">\(N\)</span>接近<span class="math inline">\(p\)</span>时，甚至在表现出野蛮的行为 。弹性网惩罚缓解了这些问题。</p>
<div id="载入示例数据集" class="section level4">
<h4>4.1.1 载入示例数据集</h4>
<pre class="r"><code>data(BinomialExample)# 产生名为x维度为100*30的矩阵 ,名为y长度为100的int向量（0、1向量）</code></pre>
<p>这里的输入x与其他分布簇相同，对于二项Logistic回归，响应变量y应该是具有两个级别的因子，或者是计数或比例的两列矩阵</p>
</div>
<div id="拟合模型-2" class="section level4">
<h4>4.1.2 拟合模型</h4>
<p><code>glmnet</code>二项式回归的其他可选参数与高斯族的几乎相同.仅需要把函数簇改为<code>family = "binomial"</code>即可：</p>
<pre class="r"><code>fit = glmnet(x, y, family = &quot;binomial&quot;)</code></pre>
</div>
<div id="查看拟合效果-1" class="section level4">
<h4>4.1.3 查看拟合效果</h4>
<p>同样， 我们可以用<code>print</code>和<code>plot</code>函数去查看对象 , 用<code>coef</code>提取特定λ的系数，用<code>predict</code>可以做出预测 .</p>
<pre class="r"><code>plot(fit, xvar = &quot;dev&quot;, label = TRUE)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
</div>
<div id="预测-2" class="section level4">
<h4>4.1.4 预测</h4>
<p>逻辑回归的预测同高斯簇函数的用法有点不同，主要体现在参数<code>type</code>的设置上，详细概括如下：</p>
<ul>
<li>“link” 线性拟合值</li>
<li>“response” 拟合的概率值</li>
<li>“class” 给出计算出的最大概率对应的类的标签</li>
<li>“coefficients” 计算给定<code>s</code>下的系数的估计值</li>
<li>“nonzero” 返回一个list对象，该list包含每一个<code>s</code>对应非零系数的索引</li>
</ul>
<blockquote>
<p>对于“二项式”模型，预测结果仅仅是针对响应变量的第二个水平(“link”, “response”, “coefficients”, “nonzero”) (可以用<code>level</code>函数查看第二级别的类)</p>
</blockquote>
<pre class="r"><code>predict(fit, newx = x[1:5,], type = &quot;class&quot;, s = c(0.05, 0.01))
#&gt;      1   2  
#&gt; [1,] &quot;0&quot; &quot;0&quot;
#&gt; [2,] &quot;1&quot; &quot;1&quot;
#&gt; [3,] &quot;1&quot; &quot;1&quot;
#&gt; [4,] &quot;0&quot; &quot;0&quot;
#&gt; [5,] &quot;1&quot; &quot;1&quot;</code></pre>
</div>
<div id="交叉验证-3" class="section level4">
<h4>4.1.5 交叉验证</h4>
<p>逻辑回归的<code>cv.glmnet</code>的用法同高斯簇函数，<code>nfolds</code>, <code>weights</code>, <code>lambda</code>,<code>parallel</code>的设置一样，区别主要在<code>type.measure</code>：</p>
<ul>
<li>“mse” 用平方损失</li>
<li>“deviance” 用真实偏差</li>
<li>“mae” 用平均绝对误差</li>
<li>“class” 用误分类率</li>
<li>“auc” ROC曲线的下面积(这个选项仅针对两分类逻辑回归)。是现在最流行的综合考量模型性能的一种参数</li>
</ul>
<p>例如，用误分类率误差为标准做十折交叉验证，代码如下：</p>
<pre class="r"><code>cvfit = cv.glmnet(x, y, family = &quot;binomial&quot;, type.measure = &quot;class&quot;)</code></pre>
<p>用<code>plot</code>查看<code>cv.glmnet</code>生成的结果： .</p>
<pre class="r"><code>plot(cvfit)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-41-1.png" width="672" /></p>
<pre class="r"><code>cvfit$lambda.min #查看最优的λ值
#&gt; [1] 0.01116192
cvfit$lambda.1se
#&gt; [1] 0.0310587</code></pre>
<p><code>coef</code>和<code>predict</code>与高斯簇类似：</p>
<pre class="r"><code>coef(cvfit, s = &quot;lambda.min&quot;) # 如前所述，此处返回的结果仅适用于响应变量的第二个水平。
#&gt; 31 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
#&gt;                        1
#&gt; (Intercept)  0.219571058
#&gt; V1           0.127143183
#&gt; V2           0.773438290
#&gt; V3          -0.622026676
#&gt; V4          -1.249153389
#&gt; V5          -0.236036348
#&gt; V6          -1.086126630
#&gt; V7           .          
#&gt; V8          -0.662605659
#&gt; V9           0.903895120
#&gt; V10         -1.662994097
#&gt; V11         -0.069429691
#&gt; V12         -0.109197704
#&gt; V13          .          
#&gt; V14          .          
#&gt; V15          .          
#&gt; V16          0.489302060
#&gt; V17          .          
#&gt; V18         -0.123121403
#&gt; V19         -0.009732698
#&gt; V20         -0.063913565
#&gt; V21          .          
#&gt; V22          0.237278300
#&gt; V23          0.413516339
#&gt; V24         -0.040687440
#&gt; V25          0.746129316
#&gt; V26         -0.376173274
#&gt; V27         -0.168082915
#&gt; V28          0.312045065
#&gt; V29         -0.254478998
#&gt; V30          0.157077462</code></pre>
<p>As mentioned previously, the results returned here are only for the second level of the factor response.</p>
<pre class="r"><code>predict(cvfit, newx = x[1:10,], s = &quot;lambda.min&quot;, type = &quot;class&quot;)
#&gt;       1  
#&gt;  [1,] &quot;0&quot;
#&gt;  [2,] &quot;1&quot;
#&gt;  [3,] &quot;1&quot;
#&gt;  [4,] &quot;0&quot;
#&gt;  [5,] &quot;1&quot;
#&gt;  [6,] &quot;0&quot;
#&gt;  [7,] &quot;0&quot;
#&gt;  [8,] &quot;0&quot;
#&gt;  [9,] &quot;1&quot;
#&gt; [10,] &quot;1&quot;</code></pre>
</div>
</div>
<div id="多分类逻辑回归" class="section level3">
<h3>4.2 多分类逻辑回归</h3>
<p>多分类逻辑回归假定响应变量服从多项式分布, 假定响应变量有K个水平 <span class="math inline">\({\cal G}=\{1,2,\ldots,K\}\)</span>。则有</p>
<p><span class="math display">\[\mbox{Pr}(G=k|X=x)=\frac{e^{\beta_{0k}+\beta_k^Tx}}{\sum_{\ell=1}^Ke^{\beta_{0\ell}+\beta_\ell^Tx}}.\]</span></p>
<p><span class="math inline">\({Y}\)</span> 应该是 <span class="math inline">\(N \times K\)</span> 的响应矩阵（把离散变量进行one-hot编码即可） ,那么带弹性网惩罚项的非负对数似然函数如下：
<span class="math display">\[
\ell(\{\beta_{0k},\beta_{k}\}_1^K) = -\left[\frac{1}{N} \sum_{i=1}^N \Big(\sum_{k=1}^Ky_{il} (\beta_{0k} + x_i^T \beta_k)- \log \big(\sum_{k=1}^K e^{\beta_{0k}+x_i^T \beta_k}\big)\Big)\right] +\lambda \left[ (1-\alpha)||\beta||_F^2/2 + \alpha\sum_{j=1}^p||\beta_j||_q\right].
\]</span>
这里β是一个<span class="math inline">\(p\times K\)</span>维的系数矩阵 <span class="math inline">\(\beta_k\)</span> 是其中的第<span class="math inline">\(k\)</span>列,表示第<span class="math inline">\(k\)</span>个模型对应模型的系数 , <span class="math inline">\(\beta_j\)</span> 第<span class="math inline">\(j\)</span>行，表示第<span class="math inline">\(j\)</span>个变量前面的系数。</p>
<p>后面的惩罚项 <span class="math inline">\(||\beta_j||_q\)</span>, 有两种情形 <span class="math inline">\(q\in \{1,2\}\)</span>.当q=1时，它是一个lasso惩罚项；当q=2时，它是一个grouped-lasso惩罚项。</p>
<div id="载入示例数据集-1" class="section level4">
<h4>4.2.1 载入示例数据集</h4>
<p>首先载入数据集：</p>
<pre class="r"><code>data(MultinomialExample)# 产生名为x维度为100*30的矩阵 ,名为y长度为100的数字向量（水平1,2,3组成）训练是内部自动转换</code></pre>
</div>
<div id="拟合模型-3" class="section level4">
<h4>4.2.2 拟合模型</h4>
<p>多分类逻辑回归的模型拟和二分类逻辑回归类似，只是这里新增加了一个特殊的参数<code>type.multinomial</code>，当<code>type.multinomial = "grouped"</code>时，模型拟合时会让每个变量前面的系数全为0或者全不为零，其实就是对于每个类建立逻辑回归时所用到的变量完全相同。</p>
<pre class="r"><code>fit = glmnet(x, y, family = &quot;multinomial&quot;, type.multinomial = &quot;grouped&quot;)</code></pre>
</div>
<div id="查看拟合效果-2" class="section level4">
<h4>4.2.3 查看拟合效果</h4>
<p>用<code>plot</code>查看模型拟合结果：</p>
<pre class="r"><code>plot(fit, xvar = &quot;lambda&quot;, label = TRUE, type.coef = &quot;2norm&quot;)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-47-1.png" width="672" /></p>
<pre class="r"><code>plot(fit, xvar = &quot;lambda&quot;, label = TRUE, type.coef = &quot;coef&quot;)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-47-2.png" width="672" /><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-47-3.png" width="672" /><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-47-4.png" width="672" /></p>
<p>这里<code>xvar</code>和<code>label</code>的使用和之前相同，但是多了一个<code>type.coef</code>选项，这个选项仅适用于对多分类逻辑回归以及多响应变量线性回归，若<code>type.coef = "coef"</code>会用多张图分别展示每个响应变量的系数，若<code>type.coef = "2norm"</code>则会展示系数的L2-范数。</p>
</div>
<div id="交叉验证和预测" class="section level4">
<h4>4.2.4 交叉验证和预测</h4>
<p>我们同样也可以做交叉验证：</p>
<pre class="r"><code>library(doParallel)
# Windows System
cl&lt;-makeCluster(7)
registerDoParallel(cl)
cvfit=cv.glmnet(x, y, family=&quot;multinomial&quot;, type.multinomial = &quot;grouped&quot;, parallel = TRUE)
stopCluster(cl)
plot(cvfit)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<p>用拟合的模型来预测：</p>
<pre class="r"><code>predict(cvfit, newx = x[1:10,], s = &quot;lambda.min&quot;, type = &quot;class&quot;)
#&gt;       1  
#&gt;  [1,] &quot;3&quot;
#&gt;  [2,] &quot;2&quot;
#&gt;  [3,] &quot;2&quot;
#&gt;  [4,] &quot;3&quot;
#&gt;  [5,] &quot;1&quot;
#&gt;  [6,] &quot;3&quot;
#&gt;  [7,] &quot;3&quot;
#&gt;  [8,] &quot;1&quot;
#&gt;  [9,] &quot;1&quot;
#&gt; [10,] &quot;2&quot;</code></pre>
</div>
</div>
</div>
<div id="泊松回归" class="section level2">
<h2>5 泊松回归</h2>
<p>泊松回归经常会用到计数模型中，假定其误差满足泊松分布。</p>
<p>经常用其均值的对数来建模：<span class="math inline">\(\log \mu(x) = \beta_0+\beta&#39; x\)</span>.</p>
<p>给定 <span class="math inline">\(\{x_i,y_i\}_1^N\)</span>下的对数似然为:
<span class="math display">\[
l(\beta|X, Y) = \sum_{i=1}^N (y_i (\beta_0+\beta&#39; x_i) - e^{\beta_0+\beta^Tx_i}.
\]</span>
于是问题变成优化如下带惩罚的对数似然：
<span class="math display">\[
\min_{\beta_0,\beta} -\frac1N l(\beta|X, Y)  + \lambda \left((1-\alpha) \sum_{i=1}^N \beta_i^2/2) +\alpha \sum_{i=1}^N |\beta_i|\right).
\]</span></p>
<div id="加载数据集" class="section level3">
<h3>5.1 加载数据集</h3>
<pre class="r"><code>data(PoissonExample)# 产生名为x维度为500*20的矩阵 ,名为y长度为500的数字向量,全是大于0的数字（泊松函数也是大于0的函数）</code></pre>
</div>
<div id="拟合模型-4" class="section level3">
<h3>5.2 拟合模型</h3>
<p>采用<code>glmnet</code>函数，设置<code>family = "poisson"</code>：</p>
<pre class="r"><code>fit = glmnet(x, y, family = &quot;poisson&quot;)</code></pre>
</div>
<div id="查看拟合效果-3" class="section level3">
<h3>5.3 查看拟合效果</h3>
<pre class="r"><code>plot(fit)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
</div>
<div id="预测-3" class="section level3">
<h3>5.4 预测</h3>
<p>用<code>predict</code>做预测,在参数选项的设置中，主要是<code>type</code>存在一些差异，做出说明如下：</p>
<ul>
<li>“link” 给出线性拟合值</li>
<li>“response” 给出拟合的均值</li>
<li>“coefficients” 计算给定<code>s</code>下的系数，也可以直接用<code>coef</code>函数</li>
<li>“nonzero” 返回一个list对象，该list包含每一个<code>s</code>对应非零系数的索引</li>
</ul>
<pre class="r"><code>coef(fit, s = 1)
#&gt; 21 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
#&gt;                       1
#&gt; (Intercept)  0.61123371
#&gt; V1           0.45819758
#&gt; V2          -0.77060709
#&gt; V3           1.34015128
#&gt; V4           0.04350500
#&gt; V5          -0.20325967
#&gt; V6           .         
#&gt; V7           .         
#&gt; V8           .         
#&gt; V9           .         
#&gt; V10          .         
#&gt; V11          .         
#&gt; V12          0.01816309
#&gt; V13          .         
#&gt; V14          .         
#&gt; V15          .         
#&gt; V16          .         
#&gt; V17          .         
#&gt; V18          .         
#&gt; V19          .         
#&gt; V20          .
predict(fit, newx = x[1:5,], type = &quot;response&quot;, s = c(0.1,1))
#&gt;               1          2
#&gt; [1,]  2.4944232  4.4263365
#&gt; [2,] 10.3513120 11.0586174
#&gt; [3,]  0.1179704  0.1781626
#&gt; [4,]  0.9713412  1.6828778
#&gt; [5,]  1.1133472  1.9934537</code></pre>
<p>我们同样也可以做交叉验证：</p>
<pre class="r"><code>cvfit = cv.glmnet(x, y, family = &quot;poisson&quot;)</code></pre>
<p>选项与高斯族几乎相同，除了 <code>type.measure</code></p>
<ul>
<li><code>cv.glmnet</code>中<code>type.measure</code>的设置：
<ul>
<li>“deviance” 偏差</li>
<li>“mse” 均方误差</li>
<li>“mae” 平均绝对误差</li>
</ul></li>
</ul>
<p>绘制<code>cv.glmnet</code>对象。</p>
<pre class="r"><code>plot(cvfit)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-55-1.png" width="672" /></p>
<p>提取最优λ对应的模型系数：</p>
<pre class="r"><code>opt.lam = c(cvfit$lambda.min, cvfit$lambda.1se)
coef(cvfit, s = opt.lam)
#&gt; 21 x 2 sparse Matrix of class &quot;dgCMatrix&quot;
#&gt;                        1            2
#&gt; (Intercept)  0.070584044  0.200007601
#&gt; V1           0.609229006  0.571833738
#&gt; V2          -0.972486782 -0.927099773
#&gt; V3           1.509004735  1.466409189
#&gt; V4           0.225598648  0.192138902
#&gt; V5          -0.328715117 -0.301559295
#&gt; V6           .            .          
#&gt; V7          -0.005088443  .          
#&gt; V8           .            .          
#&gt; V9           .            .          
#&gt; V10          0.006071218  .          
#&gt; V11          .            .          
#&gt; V12          0.029070537  0.025801372
#&gt; V13         -0.014882186  .          
#&gt; V14          0.020864442  .          
#&gt; V15          .            .          
#&gt; V16          0.008606586  .          
#&gt; V17          .            .          
#&gt; V18          .            .          
#&gt; V19         -0.023621751  .          
#&gt; V20          0.011789503  0.009436611</code></pre>
<p>可以使用<code>predict</code>进行预测，方法类似，在重复</p>
</div>
</div>
<div id="cox模型" class="section level2">
<h2>6 Cox模型</h2>
<p>不是很了解。</p>
<p>The Cox proportional hazards model is commonly used for the study of the relationship beteween predictor variables and survival time. In the usual survival analysis framework, we have data of the form <span class="math inline">\((y_1, x_1, \delta_1), \ldots, (y_n, x_n, \delta_n)\)</span> where <span class="math inline">\(y_i\)</span>, the observed time, is a time of failure if <span class="math inline">\(\delta_i\)</span> is 1 or right-censoring if <span class="math inline">\(\delta_i\)</span> is 0. We also let <span class="math inline">\(t_1 &lt; t_2 &lt; \ldots &lt; t_m\)</span> be the increasing list of unique failure times, and <span class="math inline">\(j(i)\)</span> denote the index of the observation failing at time <span class="math inline">\(t_i\)</span>.</p>
<p>The Cox model assumes a semi-parametric form for the hazard
<span class="math display">\[
h_i(t) = h_0(t) e^{x_i^T \beta},
\]</span>
where <span class="math inline">\(h_i(t)\)</span> is the hazard for patient <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span>, <span class="math inline">\(h_0(t)\)</span> is a shared baseline hazard, and <span class="math inline">\(\beta\)</span> is a fixed, length <span class="math inline">\(p\)</span> vector. In the classic setting <span class="math inline">\(n \geq p\)</span>, inference is made via the partial likelihood
<span class="math display">\[
L(\beta) = \prod_{i=1}^m \frac{e^{x_{j(i)}^T \beta}}{\sum_{j \in R_i} e^{x_j^T \beta}},
\]</span>
where <span class="math inline">\(R_i\)</span> is the set of indices <span class="math inline">\(j\)</span> with <span class="math inline">\(y_j \geq t_i\)</span> (those at risk at time <span class="math inline">\(t_i\)</span>).</p>
<p>Note there is no intercept in the Cox mode (its built into the baseline hazard, and like it, would cancel in the partial likelihood.)</p>
<p>We penalize the negative log of the partial likelihood, just like the other models, with an elastic-net penalty.</p>
<div id="载入数据集" class="section level3">
<h3>6.1 载入数据集</h3>
<p>同样地，我们加载预先生成好的样本数据和响应变量，但是这里需要注意的是，这里采用了生存分析的分析框架，输入数据略有差别。首先，我们加载数据集：</p>
<pre class="r"><code>data(CoxExample)# 产生名为x的矩阵，其维度为1000*30 ，名为y的矩阵，其维度为1000*2
y[1:5,] # status列表示time列对应下的状态，第一列必须是数值型的时间，第二列参数是逻辑向量，0/1表示死亡与否
#&gt;            time status
#&gt; [1,] 1.76877757      1
#&gt; [2,] 0.54528404      1
#&gt; [3,] 0.04485918      0
#&gt; [4,] 0.85032298      0
#&gt; [5,] 0.61488426      1</code></pre>
<p>可以看到加载的数据还是包含自变量x以及响应变量y两部分：x是n×p维的矩阵；不同的是y，y为<span class="math inline">\(n \times 1\)</span>维的矩阵，其中名为<code>time</code>的列是观察时间，名为<code>status</code>的列为该观察时间下对应的状态，0表示生成，1表示死亡。</p>
</div>
<div id="拟合模型-5" class="section level3">
<h3>6.2 拟合模型</h3>
<p>同样用<code>glmnet</code>建模:</p>
<pre class="r"><code>fit = glmnet(x, y, family = &quot;cox&quot;)</code></pre>
</div>
<div id="查看拟合效果-4" class="section level3">
<h3>6.3 查看拟合效果</h3>
<pre class="r"><code>plot(fit)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
<p>提取给定 <span class="math inline">\(\lambda\)</span>下对应的系数：</p>
<pre class="r"><code>coef(fit, s = 0.05)
#&gt; 30 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
#&gt;               1
#&gt; V1   0.37693638
#&gt; V2  -0.09547797
#&gt; V3  -0.13595972
#&gt; V4   0.09814146
#&gt; V5  -0.11437545
#&gt; V6  -0.38898545
#&gt; V7   0.24291400
#&gt; V8   0.03647596
#&gt; V9   0.34739813
#&gt; V10  0.03865115
#&gt; V11  .         
#&gt; V12  .         
#&gt; V13  .         
#&gt; V14  .         
#&gt; V15  .         
#&gt; V16  .         
#&gt; V17  .         
#&gt; V18  .         
#&gt; V19  .         
#&gt; V20  .         
#&gt; V21  .         
#&gt; V22  .         
#&gt; V23  .         
#&gt; V24  .         
#&gt; V25  .         
#&gt; V26  .         
#&gt; V27  .         
#&gt; V28  .         
#&gt; V29  .         
#&gt; V30  .</code></pre>
<p>由于Cox模型不常用于预测，所以没有给出预测的样例 。如果需要，可以参考帮助文件<code>help(predict.glmnet)</code>。</p>
</div>
<div id="交叉验证-4" class="section level3">
<h3>6.4 交叉验证</h3>
<p>用<code>cv.glmnet</code>做K折交叉验证时，<code>type.measure</code>的选项仅支持“deviance”：</p>
<pre class="r"><code>cvfit = cv.glmnet(x, y, family = &quot;cox&quot;)</code></pre>
<pre class="r"><code>plot(cvfit)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-62-1.png" width="672" /></p>
<p>提取最优的 <span class="math inline">\(\lambda\)</span> 值</p>
<pre class="r"><code>cvfit$lambda.min
#&gt; [1] 0.02107668
cvfit$lambda.1se
#&gt; [1] 0.05343706</code></pre>
<p>提取模型系数：</p>
<pre class="r"><code>coef.min = coef(cvfit, s = &quot;lambda.min&quot;)
active.min = which(coef.min != 0)
index.min = coef.min[active.min]</code></pre>
<pre class="r"><code>index.min
#&gt;  [1]  0.47296769 -0.16213158 -0.20518470  0.16374470 -0.17544445 -0.47500198
#&gt;  [7]  0.32076305  0.08339592  0.43422644  0.10423130  0.01054257 -0.01125802
#&gt; [13] -0.01541834
coef.min
#&gt; 30 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
#&gt;               1
#&gt; V1   0.47296769
#&gt; V2  -0.16213158
#&gt; V3  -0.20518470
#&gt; V4   0.16374470
#&gt; V5  -0.17544445
#&gt; V6  -0.47500198
#&gt; V7   0.32076305
#&gt; V8   0.08339592
#&gt; V9   0.43422644
#&gt; V10  0.10423130
#&gt; V11  .         
#&gt; V12  .         
#&gt; V13  0.01054257
#&gt; V14  .         
#&gt; V15  .         
#&gt; V16  .         
#&gt; V17 -0.01125802
#&gt; V18  .         
#&gt; V19  .         
#&gt; V20  .         
#&gt; V21  .         
#&gt; V22  .         
#&gt; V23  .         
#&gt; V24  .         
#&gt; V25 -0.01541834
#&gt; V26  .         
#&gt; V27  .         
#&gt; V28  .         
#&gt; V29  .         
#&gt; V30  .</code></pre>
<p><a href="#top">Back to Top</a></p>
<p><a id="spa"></a></p>
</div>
</div>
<div id="稀疏矩阵" class="section level2">
<h2>7 稀疏矩阵</h2>
<p>除了<code>cox</code>模型外，<code>glmnet</code>均支持稀疏矩阵作为输入，它的用法同常规矩阵的用法相同。</p>
<p>我们加载一个稀疏矩阵示例：</p>
<p>我们加载一个稀疏矩阵示例：</p>
<pre class="r"><code>data(SparseExample)</code></pre>
<p>加载的数据<code>x</code>为100*20的一个稀疏矩阵，<code>y</code>为响应变量(长度为100的向量）。</p>
<pre class="r"><code>class(x)
#&gt; [1] &quot;dgCMatrix&quot;
#&gt; attr(,&quot;package&quot;)
#&gt; [1] &quot;Matrix&quot;</code></pre>
<p>创建稀疏矩阵有两种方式，一种方式是采用<code>sparseMatrix</code>生成；还有一种方式是直接采用<code>Matrix</code>来构建。</p>
<p>当输入是稀疏矩阵时，调用<code>glmnet</code>的方式跟普通矩阵没有差别：</p>
<pre class="r"><code>fit = glmnet(x, y)</code></pre>
<p>交叉验证也一样：</p>
<pre class="r"><code>cvfit = cv.glmnet(x, y)
plot(cvfit)</code></pre>
<p><img src="/post/2018-09-13-glmnet1_files/figure-html/unnamed-chunk-69-1.png" width="672" /></p>
<p>稀疏矩阵除了可以用作<code>glmnet</code>的输入<code>x</code>，还可以用作<code>predict</code>函数的输入<code>newx</code>，我们来看看如下的例子：</p>
<pre class="r"><code>i = sample(1:5, size = 25, replace = TRUE)
j = sample(1:20, size = 25, replace = TRUE)
x = rnorm(25)
nx = sparseMatrix(i = i, j = j, x = x, dims = c(5, 20))
predict(cvfit, newx = nx, s = &quot;lambda.min&quot;)
#&gt;               1
#&gt; [1,]  0.8286576
#&gt; [2,] -0.1938951
#&gt; [3,]  0.7690298
#&gt; [4,] -0.4358310
#&gt; [5,] -0.1450590</code></pre>
<pre class="r"><code>sessionInfo()
#&gt; R version 4.0.2 (2020-06-22)
#&gt; Platform: x86_64-apple-darwin17.0 (64-bit)
#&gt; Running under: macOS Mojave 10.14.5
#&gt; 
#&gt; Matrix products: default
#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
#&gt; 
#&gt; locale:
#&gt; [1] zh_CN.UTF-8/zh_CN.UTF-8/zh_CN.UTF-8/C/zh_CN.UTF-8/zh_CN.UTF-8
#&gt; 
#&gt; attached base packages:
#&gt; [1] parallel  stats     graphics  grDevices utils     datasets  methods  
#&gt; [8] base     
#&gt; 
#&gt; other attached packages:
#&gt; [1] doParallel_1.0.15 doMC_1.3.6        iterators_1.0.12  foreach_1.5.0    
#&gt; [5] glmnet_4.0-2      Matrix_1.2-18    
#&gt; 
#&gt; loaded via a namespace (and not attached):
#&gt;  [1] knitr_1.29       magrittr_1.5     splines_4.0.2    lattice_0.20-41 
#&gt;  [5] rlang_0.4.7      stringr_1.4.0    tools_4.0.2      grid_4.0.2      
#&gt;  [9] xfun_0.17        htmltools_0.5.0  yaml_2.2.1       survival_3.1-12 
#&gt; [13] digest_0.6.25    bookdown_0.20    codetools_0.2-16 shape_1.4.5     
#&gt; [17] evaluate_0.14    rmarkdown_2.3    blogdown_0.20    stringi_1.4.6   
#&gt; [21] compiler_4.0.2</code></pre>
<p>参考：<a href="https://web.stanford.edu/~hastie/glmnet/glmnet_beta.html" class="uri">https://web.stanford.edu/~hastie/glmnet/glmnet_beta.html</a></p>
</div>

        </section>
    </div>
    <br>
    
    




<span id="/post/2018-09-13-glmnet1/" class="leancloud_visitors" data-flag-title="glmnet包解读1">
  <span class="post-meta-item-text">文章总阅读量 </span>
  <span class="leancloud-visitors-count"><i class="leancloud-visitors-count"></i></span>次;
  <p></p>
</span>



    

    
    
    <button id="edit-button" class="icon-button" type="button" title="Fork and edit" aria-label="Fork and edit" aria-haspopup="true" aria-expanded="false" aria-controls="edit">
        <i class="fa fa-edit">编辑本文</i>
    </button>
    
    
    

    <br>
    <hr>
    <li style="float:left;list-style:none">
        
        <a class="previous" href="/post/2018-08-31-%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81-%E5%93%91%E5%8F%98%E9%87%8F/"> 上一篇: 独热编码--哑变量</a>
        
    </li>
    <li style="float:right;list-style:none">
        
        <a class="next" href="/post/2018-11-14-r%E9%87%91%E8%9E%8D%E5%88%86%E6%9E%90%E4%B8%8Evar/"> 下一篇: R金融分析以及VaR</a>
        
    </li>
     
    
    <script src="/js/copyCode.js"></script>
    <script src="/js/tooltips.js"></script>
    
   
    <script>
    [].slice.call(document.querySelectorAll('table')).forEach(function(el) {
        var wrapper = document.createElement('div');
        wrapper.className = 'table-area';
        el.parentNode.insertBefore(wrapper, el);
        el.parentNode.removeChild(el);
        wrapper.appendChild(el);
        $("table").wrap("<div class='table-area'></div>");
    })
    </script>

    
<br>
<hr>


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-111691389-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-111691389-1');
</script>




      
      
      

       
      
      
      <script>
              document.getElementById("edit-button").addEventListener("click", function () {
                  var editWindow = window.open("https:\/\/github.com\/zoushucai\/blogmmm/edit/master/content/post\/2018-09-13-glmnet1.html");
              });</script>
      
          




<script>
  function resizeIframe(obj) {
    obj.style.height = obj.contentWindow.document.body.scrollHeight + 'px';
  } 
</script>



    </style>
    <script type="text/javascript">
    function showdiv(){
        document.getElementById("divtocTableOfContents").style.display="block";
        document.getElementById("strHref").innerHTML="目录收起-";
        document.getElementById('divTableOfContents').style.width="22%";
        document.getElementById('divTableOfContents').style.height="55%";
        document.getElementById('divTableOfContents').style.top="25%";
        document.getElementById('divTableOfContents').style.bottom="5%";
        document.getElementById("strHref").href="javascript:hidediv()";
    }
    function hidediv(){
        document.getElementById("divtocTableOfContents").style.display="none";
        document.getElementById("strHref").innerHTML="目录展开+";
        document.getElementById("strHref").href="javascript:showdiv()";
        document.getElementById('divTableOfContents').style.width="10%";
        document.getElementById('divTableOfContents').style.height="5%";
    }
    </script>
</body>

</html>
</div> 







    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/mathtex-script-type.min.js" integrity="sha384-LJ2FmexL77rmGm6SIpxq7y+XA6bkLzGZEgCywzKOZG/ws4va9fUVu2neMjvc3zdv" crossorigin="anonymous"></script>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
            delimiters: [
                            {left: "$$", right: "$$", display: true},
                            {left: "$", right: "$", display: false},
                            {left: "\\(", right: "\\)", display: false},
                            {left: "\\[", right: "\\]", display: true}
                        ]
            });
        });
    </script>













<br>
<div class="inner">
              
            
          
          
  
          
  
  <div id="vcomments"></div>
  
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  
  <script src='//unpkg.com/valine/dist/Valine.min.js'></script>
  <script type="text/javascript">
    new Valine({
        el: '#vcomments' ,
        appId: 'HfHPKPkLa0cBEDPcdBAHuqMv-gzGzoHsz',
        appKey: 'r5RJAasN8e0mB9sq6y9pEcX0',
        lang:'zh-CN',
        notify:  false , 
        verify:  false  ,
        avatar:'identicon', 
        placeholder: '说点什么吧...',
        visitor:  true 
    });
  </script>

</div>

<br>
<br>
<footer>
    <p style="float:right;margin-right: 5%;margin-top: 0%;">
        &copy; 2021 <a href="https://github.com/zoushucai">zsc</a>
      </p>
</footer>
<br>
<br>


